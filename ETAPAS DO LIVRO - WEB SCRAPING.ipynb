{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#BeautifulSoup \n",
    "\n",
    "Sua estrutura\n",
    "- html\n",
    "- head\n",
    "- title\n",
    "- body\n",
    "- h1\n",
    "- div \n",
    "Os parsers - na maioria das vezes não terá diferença\n",
    ".parser\n",
    ".lxml (usadd para trabalhar com códigos html confusos ou mal formatados. Ele corrige as tags sem fechamento) ele é mais rápido mais precisa ser insalado separadamente\n",
    ".html5lib (é igual ao lxml porém é mais lento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<title>A Useful Page</title>\n",
      "</head>\n",
      "<body>\n",
      "<h1>An Interesting Title</h1>\n",
      "<div>\n",
      "Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n",
      "</div>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "html= urlopen('https://www.pythonscraping.com/pages/page1.html')\n",
    "bs4= BeautifulSoup(html, 'html.parser')\n",
    "print(bs4.html) # vai me retornar a primeira instancia da pagina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FAZER ASSIM É MELHOR PARA SE EVITAR ERRO NA PÁGINA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<title>A Useful Page</title>\n",
      "</head>\n",
      "<body>\n",
      "<h1>An Interesting Title</h1>\n",
      "<div>\n",
      "Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n",
      "</div>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "def getTitle(url):\n",
    "    try:\n",
    "        html= urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        return None\n",
    "    try:\n",
    "        bs4= BeautifulSoup(html, 'html.parser')\n",
    "        title= bs4.html\n",
    "    except AttributeError as e:\n",
    "        return None\n",
    "    return title\n",
    "\n",
    "title= getTitle('https://www.pythonscraping.com/pages/page1.html')\n",
    "if title == None:\n",
    "    print('Titulo não foi encontrado')\n",
    "else:\n",
    "    print(title)\n",
    "# isso monstra oq o beautifulsoup faz com o arquivo da pagina. quebra ele em partes  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMO COLETAR o texto desse site "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "html= urlopen('https://www.pythonscraping.com/pages/page1.html')\n",
    "bs4= BeautifulSoup(html.read(), 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "namelist= bs4.findAll(\"div\")\n",
    "for name in namelist:\n",
    "    print(name.get_text()) # get_text remove todas as tags que não sao texto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTRAINDO O TITULO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "nametitle= bs4.findAll('h1')\n",
    "for title in nametitle :\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Interesting Title\n"
     ]
    }
   ],
   "source": [
    "nametitle= bs4.findAll('h1')\n",
    "for title in nametitle :\n",
    "    print(title.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTRAINDO IMAGEM (img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\dulor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.18.1)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\dulor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (2.1.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\dulor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (0.24.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\dulor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\dulor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (2023.11.17)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\dulor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (4.10.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\dulor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\dulor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\dulor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (3.6)\n",
      "Requirement already satisfied: outcome in c:\\users\\dulor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\dulor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\dulor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\dulor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\dulor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dulor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\dulor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Configurando o WebDriver (certifique-se de ter o WebDriver adequado instalado)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Abrindo a página do Google\n",
    "driver.get(\"https://www.google.com/\")\n",
    "\n",
    "# Encontrando o elemento pelo XPath\n",
    "img_element = driver.find_element(By.XPATH, '//img[@class=\"lnXdpd\"]')\n",
    "\n",
    "# Obtendo o texto do atributo alt\n",
    "alt_text = img_element.get_attribute(\"alt\")\n",
    "\n",
    "# Imprimindo o resultado\n",
    "print(alt_text)\n",
    "\n",
    "# Fechando o navegador\n",
    "driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Item Title\n",
      "\n",
      "Description\n",
      "\n",
      "Cost\n",
      "\n",
      "Image\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Vegetable Basket\n",
      "\n",
      "This vegetable basket is the perfect gift for your health conscious (or overweight) friends!\n",
      "Now with super-colorful bell peppers!\n",
      "\n",
      "$15.00\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Russian Nesting Dolls\n",
      "\n",
      "Hand-painted by trained monkeys, these exquisite dolls are priceless! And by \"priceless,\" we mean \"extremely expensive\"! 8 entire dolls per set! Octuple the presents!\n",
      "\n",
      "$10,000.52\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Fish Painting\n",
      "\n",
      "If something seems fishy about this painting, it's because it's a fish! Also hand-painted by trained monkeys!\n",
      "\n",
      "$10,005.00\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Dead Parrot\n",
      "\n",
      "This is an ex-parrot! Or maybe he's only resting?\n",
      "\n",
      "$0.50\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Mystery Box\n",
      "\n",
      "If you love suprises, this mystery box is for you! Do not place on light-colored surfaces. May cause oil staining. Keep your friends guessing!\n",
      "\n",
      "$1.50\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "html= urlopen('https://www.pythonscraping.com/pages/page3.html')\n",
    "bs4= BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "for child in bs4.find('table',{'id':'giftList'}).children:\n",
    "    print(child.get_text())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
