{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#BeautifulSoup \n",
    "\n",
    "Sua estrutura\n",
    "- html\n",
    "- head\n",
    "- title\n",
    "- body\n",
    "- h1\n",
    "- div \n",
    "Os parsers - na maioria das vezes não terá diferença\n",
    ".parser\n",
    ".lxml (usadd para trabalhar com códigos html confusos ou mal formatados. Ele corrige as tags sem fechamento) ele é mais rápido mais precisa ser insalado separadamente\n",
    ".html5lib (é igual ao lxml porém é mais lento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<title>A Useful Page</title>\n",
      "</head>\n",
      "<body>\n",
      "<h1>An Interesting Title</h1>\n",
      "<div>\n",
      "Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n",
      "</div>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "html= urlopen('https://www.pythonscraping.com/pages/page1.html')\n",
    "bs4= BeautifulSoup(html, 'html.parser')\n",
    "print(bs4.html) # vai me retornar a primeira instancia da pagina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FAZER ASSIM É MELHOR PARA SE EVITAR ERRO NA PÁGINA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<title>A Useful Page</title>\n",
      "</head>\n",
      "<body>\n",
      "<h1>An Interesting Title</h1>\n",
      "<div>\n",
      "Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n",
      "</div>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "def getTitle(url):\n",
    "    try:\n",
    "        html= urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        return None\n",
    "    try:\n",
    "        bs4= BeautifulSoup(html, 'html.parser')\n",
    "        title= bs4.html\n",
    "    except AttributeError as e:\n",
    "        return None\n",
    "    return title\n",
    "\n",
    "title= getTitle('https://www.pythonscraping.com/pages/page1.html')\n",
    "if title == None:\n",
    "    print('Titulo não foi encontrado')\n",
    "else:\n",
    "    print(title)\n",
    "# isso monstra oq o beautifulsoup faz com o arquivo da pagina. quebra ele em partes  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMO COLETAR o texto desse site "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "html= urlopen('https://www.pythonscraping.com/pages/page1.html')\n",
    "bs4= BeautifulSoup(html.read(), 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "namelist= bs4.findAll(\"div\")\n",
    "for name in namelist:\n",
    "    print(name.get_text()) # get_text remove todas as tags que não sao texto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTRAINDO O TITULO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "nametitle= bs4.findAll('h1')\n",
    "for title in nametitle :\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Interesting Title\n"
     ]
    }
   ],
   "source": [
    "nametitle= bs4.findAll('h1')\n",
    "for title in nametitle :\n",
    "    print(title.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTRAINDO IMAGEM (img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Configurando o WebDriver (certifique-se de ter o WebDriver adequado instalado)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Abrindo a página do Google\n",
    "driver.get(\"https://www.google.com/\")\n",
    "\n",
    "# Encontrando o elemento pelo XPath\n",
    "img_element = driver.find_element(By.XPATH, '//img[@class=\"lnXdpd\"]')\n",
    "\n",
    "# Obtendo o texto do atributo alt\n",
    "alt_text = img_element.get_attribute(\"alt\")\n",
    "\n",
    "# Imprimindo o resultado\n",
    "print(alt_text)\n",
    "\n",
    "# Fechando o navegador\n",
    "driver.quit()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
